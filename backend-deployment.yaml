apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    name: backend
  name: backend
spec:
  replicas: 1
  selector:
    matchLabels:
      name: pod-backend
  template:
    metadata:
      labels:
        name: pod-backend
      name: backend
    spec:
      containers:
      - image: ertis/kafka-ml-backend:v1.3  # If you want to use our builded image at Docker Hub.
    # - image: localhost:5000/backend       # If you want to use your local build image.
        name: backend
        ports:
        - containerPort: 8000
        imagePullPolicy: IfNotPresent
        env:
        - name: BOOTSTRAP_SERVERS
          value: kafka-cluster:9092
        - name: CONTROL_TOPIC
          value: control
        - name: KUBE_NAMESPACE
          value: kafkaml
        - name: TENSORFLOW_TRAINING_MODEL_IMAGE
          value: ertis/kafka-ml-tensorflow_model_training:v1.3      # If you want to use our builded image at Docker Hub.
        # value: ertis/kafka-ml-tensorflow_model_training:v1.3-gpu  # If you want to use our builded image at Docker Hub with GPU Support.
        # value: localhost:5000/tensorflow_model_training           # If you want to use your local build image.
        - name: TENSORFLOW_INFERENCE_MODEL_IMAGE
          value: ertis/kafka-ml-tensorflow_model_inference:v1.1
        # value: ertis/kafka-ml-tensorflow_model_inference:v1.1-gpu # If you want to use our builded image at Docker Hub with GPU Support.
        # value: localhost:5000/tensorflow_model_inference          # If you want to use your local build image.          
        - name: PYTORCH_TRAINING_MODEL_IMAGE
          value: ertis/kafka-ml-pytorch_model_training:v1.1
        # value: ertis/kafka-ml-pytorch_model_training:v1.1-gpu     # If you want to use our builded image at Docker Hub with GPU Support.
        # value: localhost:5000/pytorch_model_training              # If you want to use your local build image.
        - name: PYTORCH_INFERENCE_MODEL_IMAGE
          value: ertis/kafka-ml-pytorch_model_inference:v1.0
        # value: ertis/kafka-ml-pytorch_model_inference:v1.0-gpu    # If you want to use our builded image at Docker Hub with GPU Support.
        # value: localhost:5000/pytorch_model_inference             # If you want to use your local build image.
        - name: FRONTEND_URL
          value: http://localhost
        - name: BACKEND_URL
          value: http://backend:8000
        - name: TFEXECUTOR_URL
          value: http://tfexecutor:8001/
        - name: PTHEXECUTOR_URL
          value: http://pthexecutor:8002/
        - name: ALLOWED_HOSTS
          value: 127.0.0.1,localhost,backend
        # - name: KUBE_TOKEN
        #  value: ...
        # - name: KUBE_HOST
        #  value: https://...
        # - name: SECRET_KEY
        #  value: ...
        # - name: DEBUG
        #  value: 0